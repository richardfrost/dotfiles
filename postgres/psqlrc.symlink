-- Sources:
-- https://www.citusdata.com/blog/2017/07/16/customizing-my-postgres-shell-using-psqlrc/
-- http://www.craigkerstiens.com/2013/02/21/more-out-of-psql/
-- https://robots.thoughtbot.com/an-explained-psqlrc
-- https://robots.thoughtbot.com/improving-the-command-line-postgres-experience
-- https://github.com/datachomp/dotfiles/blob/master/.psqlrc
-- https://gist.github.com/rgreenjr/3637525#file-postgres_queries_and_commands-sql

\set QUIET 1

-------------------------------------------------
-- Presentation Settings
-------------------------------------------------
\pset null 'Â¤'
\pset linestyle unicode
\pset border 2
-- \pset pager off
-- \pset format wrapped

-------------------------------------------------
-- Other Settings
-------------------------------------------------
\set PROMPT1 '%[%033[1m%][%/] # '
-- SELECT * FROM<enter>. %R shows what type of input it expects.
\set PROMPT2 '... %R > '

-- \set ON_ERROR_ROLLBACK interactive
\set COMP_KEYWORD_CASE upper
\set HISTFILE ~/.psql_history- :DBNAME
\set HISTCONTROL ignoredups
\set VERBOSITY verbose

-------------------------------------------------
-- Client Commands
-------------------------------------------------
\timing
\x auto

-- Shortcuts
\set e '\\echo'
\set p '\\pset pager'
\set s '\\set'
\set t '\\timing'
\set w '\\watch'

-- Helpers for Saved Queries
\set alias_list `sed "1,/^-- Saved Queries/d" ~/.psqlrc | egrep -o '^.set [a-z_]*' | awk '{print $2}' | sort`
\set aliases '\\echo :alias_list'
\set today 'SELECT now()::date;'

-- Variables for Saved Queries
\set site '\\set var_site'
\set table_name '\\set var_table_name'
-------------------------------------------------
-- Saved Queries
-------------------------------------------------
-- helpful queries from https://github.com/datachomp/dotfiles/blob/master/.psqlrc
\set uptime 'SELECT now() - backend_start AS uptime FROM pg_stat_activity WHERE pid = pg_backend_pid();'
-- \set show_slow_queries 'SELECT (total_time/1000/60) AS total_minutes, (total_time/calls) AS average_time, query FROM pg_stat_statements ORDER BY 1 DESC LIMIT 100;'
\set settings 'SELECT name, setting, unit, context FROM pg_settings;'
\set conninfo 'SELECT usename, count(*) FROM pg_stat_activity group by usename;'
\set activity 'SELECT datname, pid, usename, application_name,client_addr, client_hostname, client_port, query, state FROM pg_stat_activity;'
\set waits 'SELECT pg_stat_activity.pid, pg_stat_activity.query, pg_stat_activity.waiting, now() - pg_stat_activity.query_start AS \"totaltime\", pg_stat_activity.backend_start FROM pg_stat_activity WHERE pg_stat_activity.query !~ \'%IDLE%\'::text AND pg_stat_activity.waiting = true;'
\set dbsize 'SELECT datname, pg_size_pretty(pg_database_size(datname)) AS db_size, pg_database_size(datname) AS bytes FROM pg_database ORDER BY bytes DESC;'
\set tablesize 'SELECT nspname || \'.\' || relname AS table, pg_size_pretty(pg_relation_size(C.oid)) AS size, pg_relation_size(C.oid) AS bytes FROM pg_class C LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace) WHERE nspname NOT IN (\'pg_catalog\', \'information_schema\') ORDER BY pg_relation_size(C.oid) DESC LIMIT 40;'
-- \set uselesscol 'SELECT nspname, relname, attname, typname, (stanullfrac*100)::int AS null_percent, case when stadistinct &gt;= 0 then stadistinct else abs(stadistinct)*reltuples end AS \"distinct\", case 1 when stakind1 then stavalues1 when stakind2 then stavalues2 end AS \"values\" FROM pg_class c JOIN pg_namespace ns ON (ns.oid=relnamespace) JOIN pg_attribute ON (c.oid=attrelid) JOIN pg_type t ON (t.oid=atttypid) JOIN pg_statistic ON (c.oid=starelid AND staattnum=attnum) WHERE nspname NOT LIKE E\'pg\\\\_%\' AND nspname != \'information_schema\' AND relkind=\'r\' AND NOT attisdropped AND attstattarget != 0 AND reltuples &gt;= 100 AND stadistinct BETWEEN 0 AND 1 ORDER BY nspname, relname, attname;'

-- 4 helpful queries from radek http://radek.cc/2009/08/15/psqlrc-tricks-table-sizes/
\set trashindexes '( SELECT s.schemaname AS sch, s.relname AS rel, s.indexrelname AS idx, s.idx_scan AS scans, pg_size_pretty(pg_relation_size(s.relid)) AS ts, pg_size_pretty(pg_relation_size(s.indexrelid)) AS "is" FROM pg_stat_user_indexes s JOIN pg_index i ON i.indexrelid=s.indexrelid LEFT JOIN pg_constraint c ON i.indrelid=c.conrelid AND array_to_string(i.indkey, '' '') = array_to_string(c.conkey, '' '') WHERE i.indisunique is false AND pg_relation_size(s.relid) > 1000000 AND s.idx_scan < 100000 AND c.confrelid is null ORDER BY s.idx_scan ASC, pg_relation_size(s.relid) DESC );'
\set missingindexes '( SELECT src_table, dst_table, fk_name, pg_size_pretty(s_size) AS s_size, pg_size_pretty(d_size) AS d_size, d FROM ( SELECT distinct ON (1,2,3,4,5) textin(regclassout(c.conrelid)) AS src_table, textin(regclassout(c.confrelid)) AS dst_table, c.conname AS fk_name, pg_relation_size(c.conrelid) AS s_size, pg_relation_size(c.confrelid) AS d_size, array_upper(di.indkey::int[], 1) + 1 - array_upper(c.conkey::int[], 1) AS d FROM pg_constraint c LEFT JOIN pg_index di ON di.indrelid = c.conrelid AND array_to_string(di.indkey, '' '') ~ (''^'' || array_to_string(c.conkey, '' '') || ''( |$)'') JOIN pg_stat_user_tables st ON st.relid = c.conrelid WHERE c.contype = ''f'' ORDER BY 1,2,3,4,5,6 ASC) mfk WHERE mfk.d is distinct FROM 0 AND mfk.s_size > 1000000 ORDER BY mfk.s_size DESC, mfk.d DESC );'
\set rtsize '(SELECT table_schema, table_name, pg_relation_size( quote_ident( table_schema ) || \'.\' || quote_ident( table_name ) ) AS size, pg_total_relation_size( quote_ident( table_schema ) || \'.\' || quote_ident( table_name ) ) AS total_size  FROM information_schema.tables WHERE table_type = \'BASE TABLE\' AND table_schema not in (\'information_schema\', \'pg_catalog\') ORDER BY pg_relation_size( quote_ident( table_schema ) || \'.\' || quote_ident( table_name ) ) DESC, table_schema, table_name);'
-- \set tsize '(SELECT table_schema, table_name, pg_size_pretty(size) AS size, pg_size_pretty(total_size) AS total_size FROM (:rtsize) x ORDER BY x.size DESC, x.total_size DESC, table_schema, table_name);'

-- Taken from https://github.com/heroku/heroku-pg-extras
-- via https://github.com/dlamotte/dotfiles/blob/master/psqlrc
\set bloat 'SELECT tablename AS table_name, ROUND(CASE WHEN otta=0 THEN 0.0 ELSE sml.relpages/otta::numeric END,1) AS table_bloat, CASE WHEN relpages < otta THEN ''0'' ELSE pg_size_pretty((bs*(sml.relpages-otta)::bigint)::bigint) END AS table_waste, iname AS index_name, ROUND(CASE WHEN iotta=0 OR ipages=0 THEN 0.0 ELSE ipages/iotta::numeric END,1) AS index_bloat, CASE WHEN ipages < iotta THEN ''0'' ELSE pg_size_pretty((bs*(ipages-iotta))::bigint) END AS index_waste FROM ( SELECT schemaname, tablename, cc.reltuples, cc.relpages, bs, CEIL((cc.reltuples*((datahdr+ma- (CASE WHEN datahdr%ma=0 THEN ma ELSE datahdr%ma END))+nullhdr2+4))/(bs-20::float)) AS otta, COALESCE(c2.relname,''?'') AS iname, COALESCE(c2.reltuples,0) AS ituples, COALESCE(c2.relpages,0) AS ipages, COALESCE(CEIL((c2.reltuples*(datahdr-12))/(bs-20::float)),0) AS iotta FROM ( SELECT ma,bs,schemaname,tablename, (datawidth+(hdr+ma-(case when hdr%ma=0 THEN ma ELSE hdr%ma END)))::numeric AS datahdr, (maxfracsum*(nullhdr+ma-(case when nullhdr%ma=0 THEN ma ELSE nullhdr%ma END))) AS nullhdr2 FROM ( SELECT schemaname, tablename, hdr, ma, bs, SUM((1-null_frac)*avg_width) AS datawidth, MAX(null_frac) AS maxfracsum, hdr+( SELECT 1+count(*)/8 FROM pg_stats s2 WHERE null_frac<>0 AND s2.schemaname = s.schemaname AND s2.tablename = s.tablename) AS nullhdr FROM pg_stats s, ( SELECT (SELECT current_setting(''block_size'')::numeric) AS bs, CASE WHEN substring(v,12,3) IN (''8.0'',''8.1'',''8.2'') THEN 27 ELSE 23 END AS hdr, CASE WHEN v ~ ''mingw32'' THEN 8 ELSE 4 END AS ma FROM (SELECT version() AS v) AS foo) AS constants GROUP BY 1,2,3,4,5) AS foo) AS rs JOIN pg_class cc ON cc.relname = rs.tablename JOIN pg_namespace nn ON cc.relnamespace = nn.oid AND nn.nspname = rs.schemaname AND nn.nspname <> ''information_schema'' LEFT JOIN pg_index i ON indrelid = cc.oid LEFT JOIN pg_class c2 ON c2.oid = i.indexrelid) AS sml ORDER BY CASE WHEN relpages < otta THEN 0 ELSE bs*(sml.relpages-otta)::bigint END DESC;'
\set blocking 'SELECT bl.pid AS blocked_pid, ka.query AS blocking_statement, now() - ka.query_start AS blocking_duration, kl.pid AS blocking_pid, a.query AS blocked_statement, now() - a.query_start AS blocked_duration FROM pg_catalog.pg_locks bl JOIN pg_catalog.pg_stat_activity a ON bl.pid = a.pid JOIN pg_catalog.pg_locks kl JOIN pg_catalog.pg_stat_activity ka ON kl.pid = ka.pid ON bl.transactionid = kl.transactionid AND bl.pid != kl.pid WHERE not bl.granted;'
\set cache_hit 'SELECT ''index hit rate'' AS name, (sum(idx_blks_hit)) / sum(idx_blks_hit + idx_blks_read) AS ratio FROM pg_statio_user_indexes union all SELECT ''cache hit rate'' AS name, sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) AS ratio FROM pg_statio_user_tables;'
\set index_size 'SELECT relname AS name, pg_size_pretty(sum(relpages*1024)) AS size FROM pg_class WHERE reltype=0 GROUP BY relname ORDER BY sum(relpages) DESC;'
\set index_usage 'SELECT relname, CASE idx_scan WHEN 0 THEN ''Insufficient data'' ELSE (100 * idx_scan / (seq_scan + idx_scan))::text END percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables ORDER BY n_live_tup DESC;'
\set index_usage_adv 'SELECT * FROM (SELECT stat.relname AS table, stai.indexrelname AS index, CASE stai.idx_scan WHEN 0 THEN ''Insufficient data'' ELSE (100 * stai.idx_scan / (stat.seq_scan + stai.idx_scan))::text || ''%'' END hit_rate, CASE stat.idx_scan WHEN 0 THEN ''Insufficient data'' ELSE (100 * stat.idx_scan / (stat.seq_scan + stat.idx_scan))::text || ''%'' END all_index_hit_rate, ARRAY(SELECT pg_get_indexdef(idx.indexrelid, k + 1, true) FROM generate_subscripts(idx.indkey, 1) AS k ORDER BY k) AS cols, stat.n_live_tup rows_in_table FROM pg_stat_user_indexes AS stai JOIN pg_stat_user_tables AS stat ON stai.relid = stat.relid JOIN pg_index AS idx ON (idx.indexrelid = stai.indexrelid)) AS sub_inner ORDER BY rows_in_table DESC, hit_rate ASC;'
\set locks 'SELECT pg_stat_activity.pid, pg_class.relname, pg_locks.transactionid, pg_locks.granted, substr(pg_stat_activity.query,1,30) AS query_snippet, age(now(),pg_stat_activity.query_start) AS "age" FROM pg_stat_activity,pg_locks LEFT OUTER JOIN pg_class ON (pg_locks.relation = pg_class.oid) WHERE pg_stat_activity.query <> ''<insufficient privilege>'' AND pg_locks.pid=pg_stat_activity.pid AND pg_locks.mode = ''ExclusiveLock'' ORDER BY query_start;'
\set long_running_queries 'SELECT pid, now() - pg_stat_activity.query_start AS duration, query AS query FROM pg_stat_activity WHERE pg_stat_activity.query <> ''''::text AND now() - pg_stat_activity.query_start > interval ''5 minutes'' ORDER BY now() - pg_stat_activity.query_start DESC;'
\set ps 'SELECT pid, application_name AS source, age(now(),query_start) AS running_for, waiting, query AS query FROM pg_stat_activity WHERE query <> ''<insufficient privilege>'' AND state <> ''idle'' AND pid <> pg_backend_pid() ORDER BY 3 DESC;'
\set seq_scans 'SELECT relname AS name, seq_scan AS count FROM pg_stat_user_tables ORDER BY seq_scan DESC;'
\set total_index_size 'SELECT pg_size_pretty(sum(relpages*1024)) AS size FROM pg_class WHERE reltype=0;'
\set unused_indexes 'SELECT schemaname || ''.'' || relname AS table, indexrelname AS index, pg_size_pretty(pg_relation_size(i.indexrelid)) AS index_size, idx_scan AS index_scans FROM pg_stat_user_indexes ui JOIN pg_index i ON ui.indexrelid = i.indexrelid WHERE NOT indisunique AND idx_scan < 50 AND pg_relation_size(relid) > 5 * 8192 ORDER BY pg_relation_size(i.indexrelid) / nullif(idx_scan, 0) DESC NULLS FIRST, pg_relation_size(i.indexrelid) DESC;'
\set missing_indexes 'SELECT relname, seq_scan-idx_scan AS too_much_seq, case when seq_scan-idx_scan > 0 THEN ''Missing Index?'' ELSE ''OK'' END, pg_relation_size(relname::regclass) AS rel_size, seq_scan, idx_scan FROM pg_stat_all_tables WHERE schemaname=''public'' AND pg_relation_size(relname::regclass) > 80000 ORDER BY too_much_seq DESC;'

-- Other queries
\set latest_updated_at 'SELECT updated_at FROM :var_table_name ORDER BY updated_at DESC LIMIT 1;'

-- Replication
\set replication_slots 'SELECT * FROM pg_replication_slots;'

-- MX Queries
-- Vertica Merge
\set todays_vertica_merge_jobs 'SELECT j.id, t.table_name, j.start_frame, j.end_frame, j.status FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON t.id = j.vertica_merge_table_id WHERE j.created_at >= (SELECT now()::date) AND site = :\'var_site\' ORDER BY t.table_name, j.status;'
\set todays_vertica_merge_status 'SELECT  CASE  WHEN j.status = 0 then \'Pending\'  WHEN j.status = 1 then \'Started\'  WHEN j.status = 2 then \'Completed\'  WHEN j.status = 3 then \'Skipped\'  WHEN j.status = 4 then \'Failed\'  WHEN j.status = 5 then \'Completed With Errors\'  end AS status_text,  j.status, count(j.status) AS status_count  FROM vertica_merge_jobs j  INNER JOIN vertica_merge_tables t ON t.id = j.vertica_merge_table_id  WHERE j.created_at >= (SELECT now()::date) AND site = :\'var_site\'  GROUP BY j.status  ORDER BY j.status;'
\set vertica_merge_completed 'SELECT j.id, t.table_name, j.created_at, j.start_frame, j.end_frame, j.status, j.results, j.latest_updated_at FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON j.vertica_merge_table_id = t.id WHERE status = 2 AND site = :\'var_site\' ORDER BY j.id DESC;'
\set vertica_merge_completed_with_errors 'SELECT j.id, t.table_name, j.created_at, j.start_frame, j.end_frame, j.status, j.results, j.latest_updated_at FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON j.vertica_merge_table_id = t.id WHERE status = 5 AND site = :\'var_site\' ORDER BY j.id DESC;'
\set vertica_merge_failed 'SELECT j.id, t.table_name, j.created_at, j.start_frame, j.end_frame, j.status, j.results, j.latest_updated_at FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON j.vertica_merge_table_id = t.id WHERE status = 4 AND site = :\'var_site\' ORDER BY j.id DESC;'
\set vertica_merge_latest_jobs 'SELECT vmj.id, vmt.table_name, vmt.latest_updated_at, vmj.created_at, vmj.start_frame, vmj.end_frame, vmj.status, vmj.record_count, vmj.exception_count, vmj.results, vmj.latest_updated_at FROM (SELECT id, rank() OVER (PARTITION BY vertica_merge_table_id ORDER BY created_at DESC) AS pos FROM vertica_merge_jobs ) AS ss INNER JOIN vertica_merge_jobs AS vmj ON ss.id = vmj.id INNER JOIN vertica_merge_tables AS vmt ON vmj.vertica_merge_table_id = vmt.id WHERE pos <= 1 AND vmt.site = :\'var_site\' ORDER BY vmt.table_name, vmj.vertica_merge_table_id,pos;'
\set vertica_merge_pending 'SELECT j.id, t.table_name, j.created_at, j.start_frame, j.end_frame, j.status, j.results, j.latest_updated_at FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON j.vertica_merge_table_id = t.id WHERE status = 0 AND site = :\'var_site\' ORDER BY j.id DESC;'
\set vertica_merge_skipped 'SELECT j.id, t.table_name, j.created_at, j.start_frame, j.end_frame, j.status, j.results, j.latest_updated_at FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON j.vertica_merge_table_id = t.id WHERE status = 3 AND site = :\'var_site\' ORDER BY j.id DESC;'
\set vertica_merge_started 'SELECT j.id, t.table_name, j.created_at, j.start_frame, j.end_frame, j.status, j.results, j.latest_updated_at FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON j.vertica_merge_table_id = t.id WHERE status = 1 AND site = :\'var_site\' ORDER BY j.id DESC;'
\set vertica_merge_tables 'SELECT id, table_name, mergeable, updated_at, has_updated_at, latest_updated_at, is_deleted, results FROM vertica_merge_tables WHERE site = :\'var_site\' ORDER BY table_name;'
\set yesterdays_vertica_merge_jobs 'SELECT j.id, t.table_name, j.start_frame, j.end_frame, j.status FROM vertica_merge_jobs j INNER JOIN vertica_merge_tables t ON t.id = j.vertica_merge_table_id WHERE j.created_at >= (SELECT now()::date - 1) AND site = :\'var_site\' ORDER BY t.table_name, j.status;'
\set yesterdays_vertica_merge_status 'SELECT  CASE  WHEN j.status = 0 then \'Pending\'  WHEN j.status = 1 then \'Started\'  WHEN j.status = 2 then \'Completed\'  WHEN j.status = 3 then \'Skipped\'  WHEN j.status = 4 then \'Failed\'  WHEN j.status = 5 then \'Completed With Errors\'  end AS status_text,  j.status, count(j.status) AS status_count  FROM vertica_merge_jobs j  INNER JOIN vertica_merge_tables t ON t.id = j.vertica_merge_table_id  WHERE j.created_at >= (SELECT now()::date - 1) AND site = :\'var_site\'  GROUP BY j.status  ORDER BY j.status;'

\unset QUIET
